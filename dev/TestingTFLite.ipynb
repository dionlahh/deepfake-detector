{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 19:53:08.472623: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "from common.model_utils import input_size\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load TFLite model\n",
    "def load_tflite_model(model_path):\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, img_size):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_size, img_size))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \".../dev/Training Data\"\n",
    "landmark_data_folder = \".../dev/Training Landmarks Data\"\n",
    "result_folder = \".../dev/Result\"\n",
    "landmark_result_folder = \".../dev/Landmark Result\"\n",
    "models_folder = \".../dev/Benchmark Models\"\n",
    "landmark_models_folder = \".../dev/Landmark Models\"\n",
    "tuning_folder = \".../dev/Tuning\"\n",
    "landmark_tuning_folder = \".../dev/Landmark Tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"tflite/BaseB0.tflite\"\n",
    "LANDMARK = False\n",
    "\n",
    "if LANDMARK:\n",
    "    tuning_dir = landmark_tuning_folder\n",
    "    data_dir = landmark_data_folder\n",
    "    model_dir = landmark_models_folder\n",
    "    result_dir = landmark_result_folder\n",
    "else:\n",
    "    tuning_dir = tuning_folder\n",
    "    data_dir = data_folder\n",
    "    model_dir = models_folder\n",
    "    result_dir = result_folder\n",
    "\n",
    "test_path = os.path.join(\".\", data_dir, \"Test\")\n",
    "model = model_dir = \"tflite\"\n",
    "model_path = os.path.join(model_dir, f\"BaseB0.tflite\")\n",
    "model = load_tflite_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_gen = ImageDataGenerator(\n",
    "#     preprocessing_function=efn.preprocess_input\n",
    "# )\n",
    "\n",
    "\n",
    "# test_generator = test_img_gen.flow_from_directory(\n",
    "#     directory=test_path,\n",
    "#     target_size=(input_details[0]['shape'][1], input_details[0]['shape'][2]),\n",
    "#     batch_size=1,\n",
    "#     class_mode=None,\n",
    "#     shuffle=False,\n",
    "#     seed=123,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to perform inference on an image batch\n",
    "# def predict_batch(image_batch):\n",
    "#     interpreter.set_tensor(input_details[0]['index'], image_batch)\n",
    "#     interpreter.invoke()\n",
    "#     output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "#     return output_data\n",
    "\n",
    "# # Initialize variables for accuracy calculation\n",
    "# total_images = test_generator.samples\n",
    "# correct_predictions = 0\n",
    "\n",
    "# # Iterate over test data generator and perform inference\n",
    "# for i in range(total_images):\n",
    "#     image_batch = test_generator.next()\n",
    "#     predicted_scores = predict_batch(image_batch)\n",
    "#     predicted_classes = np.argmax(predicted_scores, axis=1)\n",
    "#     # You can calculate accuracy here if you have ground truth labels\n",
    "#     # Otherwise, you can print predictions for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42562 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_img_gen = ImageDataGenerator(preprocessing_function=None)  # No preprocessing for TFLite models\n",
    "\n",
    "img_size = (input_details[0]['shape'][1], input_details[0]['shape'][2])  # Define your function to get the input size based on the model type\n",
    "\n",
    "test_generator = test_img_gen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=1,  # Set batch size to 1 for TFLite inference\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "# Perform inference and evaluate model\n",
    "predicted_class_indices = []\n",
    "for i in range(len(test_generator)):\n",
    "    image_batch = test_generator.next()\n",
    "    model.set_tensor(model.get_input_details()[0]['index'], image_batch)\n",
    "    model.invoke()\n",
    "    output_data = model.get_tensor(model.get_output_details()[0]['index'])\n",
    "    predicted_class_indices.extend(np.argmax(output_data, axis=1))\n",
    "\n",
    "# Get ground truth labels\n",
    "y = test_generator.classes\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = metrics.accuracy_score(y, predicted_class_indices)\n",
    "precision = metrics.precision_score(y, predicted_class_indices, average=\"binary\")\n",
    "recall = metrics.recall_score(y, predicted_class_indices, average=\"binary\")\n",
    "auc = metrics.roc_auc_score(y, predicted_class_indices)\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Model Precision:\", precision)\n",
    "print(\"Model Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Save results to CSV\n",
    "result_dir = \"/home/FYP/dion0020/deepfake-detector/dev/tflite/results\"\n",
    "filenames = [os.path.split(i)[1] for i in test_generator.filenames]\n",
    "actual_labels = [os.path.split(i)[0] for i in test_generator.filenames]\n",
    "actual_labels = [\"0\" if label == \"manipulated\" else \"1\" for label in actual_labels]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"id\": filenames,\n",
    "    \"actual label\": actual_labels,\n",
    "    \"pred label\": predicted_class_indices\n",
    "})\n",
    "\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "results_df.to_csv(os.path.join(result_dir, model_type + \"_out.csv\"))\n",
    "\n",
    "# Save model results to JSON\n",
    "models_result = {\n",
    "    model_type: {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(result_dir, \"model_results.json\"), \"w\") as outfile:\n",
    "    json.dump(models_result, outfile)\n",
    "\n",
    "# Save model prediction results to CSV\n",
    "model_prediction_results = pd.DataFrame.from_dict(models_result, orient=\"index\")\n",
    "model_prediction_results.to_csv(os.path.join(result_dir, \"prediction_results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
