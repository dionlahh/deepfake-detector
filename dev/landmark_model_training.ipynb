{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "In this notebook, we trained 4 different EfficientNet models on the faces extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 02:51:17.305963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 02:51:17.409152: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 02:51:22.974784: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-23 02:51:22.974818: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-23 02:51:22.974838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SCSEGPU-TC1): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs\n",
    "print(\"Available GPUs:\", tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67142/191700507.py:25: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.display import set_matplotlib_formats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "from common.model_utils import build_model, input_size\n",
    "# from common.landmark_model_utils import build_model_landmarks\n",
    "\n",
    "# import packages and modules for graph plotting\n",
    "from pandas.plotting import table\n",
    "\n",
    "# setup output image format (Chrome works best)\n",
    "set_matplotlib_formats(\"svg\")\n",
    "\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if tf.test.is_gpu_available():\n",
    "#     print(\"GPU is available and in use.\")\n",
    "# else:\n",
    "#     print(\"No GPU found, using CPU.\")\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create necessary project folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'Landmark Models' already exists at ./Landmark Models\n",
      "Folder 'Landmark History' already exists at ./Landmark History\n",
      "Folder 'Result' already exists at ./Result\n",
      "Folder 'Tuning' already exists at ./Tuning\n"
     ]
    }
   ],
   "source": [
    "# Input list of folder names\n",
    "models_folder = \"Landmark Models\"\n",
    "history_folder = \"Landmark History\"\n",
    "result_folder = \"Result\"\n",
    "tuning_folder = \"Tuning\"\n",
    "data_folder = \"Training Landmarks Data\"\n",
    "folder_names = [models_folder, history_folder, result_folder, tuning_folder]\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(\".\", folder_name)\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "        print(f\"Folder '{folder_name}' created at {folder_path}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Folder '{folder_name}' already exists at {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split Data\n",
    "# # ├── Test\n",
    "# # │   ├── manipulated\n",
    "# # │   └── original\n",
    "# # ├── Training\n",
    "# # │   ├── manipulated\n",
    "# # │   └── original\n",
    "# # └── Validation\n",
    "# #     ├── manipulated\n",
    "# #     └── original\n",
    "\n",
    "# # Check if the dataset directory is already present to avoid redundant read and writes\n",
    "# isExist = os.path.exists(\"./\" + data_folder + \"/\")\n",
    "\n",
    "# if not isExist:\n",
    "#     # Creates the appropriate directory structures for training, validation and test sets.\n",
    "#     try:\n",
    "#         shutil.rmtree(\"./\" + data_folder + \"/\")\n",
    "#     except:\n",
    "#         pass  # Split Data didn't exist\n",
    "\n",
    "#     os.mkdir(\"./Split Data\")\n",
    "#     cdf = {\n",
    "#         \"Training\": 0.7,\n",
    "#         \"Validation\": 0.85,\n",
    "#         \"Test\": 1,\n",
    "#     }  # OBS! Has to be increment percentages of 5 to make batch size fit\n",
    "#     for dir in list(cdf.keys()):\n",
    "#         os.mkdir(\"./\" + data_folder + \"/{}\".format(dir))\n",
    "#         os.mkdir(\"./\" + data_folder + \"/{}/manipulated\".format(dir))\n",
    "#         os.mkdir(\"./\" + data_folder + \"/{}/original\".format(dir))\n",
    "# else:\n",
    "#     print(\"Dataset directory already exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models we want to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 02:51:24.321572: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    \"EfficientNetB0\",\n",
    "    \"EfficientNetB1\",\n",
    "    \"EfficientNetB2\",\n",
    "    \"EfficientNetB3\",\n",
    "]\n",
    "\n",
    "models = {}\n",
    "landmarks_shape = (68, 2)\n",
    "\n",
    "for model_type in model_list:\n",
    "    size = input_size(model_type)\n",
    "    models[model_type] = build_model(model_type= model_type, input_shape=(size, size, 3), hidden_layer_size=2, activation_function=\"relu\", learning_rate=0.001, dropout_rate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(model_type\u001b[38;5;241m=\u001b[39m model_type, input_shape\u001b[38;5;241m=\u001b[39m(size, size, \u001b[38;5;241m3\u001b[39m), hidden_layer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, activation_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     82\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, models_folder, model_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m from disk\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_type))\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Skip testing if there was an error in training the model\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fyp/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/fyp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:655\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    590\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    Returns an array with axes transposed.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fyp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "\n",
    "# Specify the path to the train and validation data\n",
    "trainpath = os.path.join(\".\", data_folder, \"Training\")\n",
    "valpath = os.path.join(\".\", data_folder, \"Validation\")\n",
    "\n",
    "# constant fields\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "\n",
    "models_fit_history = {}\n",
    "models_result = {}\n",
    "models_failed = []\n",
    "\n",
    "# Train the models\n",
    "for model_type in model_list:\n",
    "    error_flag = False\n",
    "    imgsize = input_size(model_type)\n",
    "\n",
    "    # Check if the model is already trained to avoid redundant processing\n",
    "    if not os.path.exists(os.path.join(\".\", models_folder, model_type + \".hdf5\")):\n",
    "        # Load data and preprocess it\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=efn.preprocess_input\n",
    "        )\n",
    "\n",
    "        train_gen = train_datagen.flow_from_directory(\n",
    "            trainpath,\n",
    "            target_size=(imgsize, imgsize),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=\"categorical\",\n",
    "        )\n",
    "        val_gen = train_datagen.flow_from_directory(\n",
    "            valpath,\n",
    "            target_size=(imgsize, imgsize),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=\"categorical\",\n",
    "        )\n",
    "\n",
    "        # load model\n",
    "        model = models[model_type]\n",
    "        model.summary()\n",
    "\n",
    "        # callbacks for early stopping and saving the best model so far based on validation loss for each epoch\n",
    "        cb_early_stopper = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "        cb_checkpointer = ModelCheckpoint(\n",
    "            filepath=os.path.join(\".\", models_folder, model_type + \".hdf5\"),\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            mode=\"auto\",\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # train model\n",
    "            fit_history = model.fit(\n",
    "                train_gen,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=val_gen,\n",
    "                callbacks=[\n",
    "                    cb_checkpointer,\n",
    "                    cb_early_stopper,\n",
    "                    ClearMemory(),\n",
    "                ],  # ClearMemory() is a custom callback to clear memory after each epoch to avoid memory leak\n",
    "            )\n",
    "\n",
    "            models_fit_history[model_type] = fit_history\n",
    "        except Exception as e:\n",
    "            models_failed.append(model_type)\n",
    "            error_flag = True\n",
    "            print(\"Encountered error while training:\", e)\n",
    "\n",
    "        history_df = pd.DataFrame(models_fit_history[model_type].history)\n",
    "        os.path.join(\".\", history_folder, model_type + \".hdf5\")\n",
    "        history_df.to_csv(\n",
    "            os.path.join(\".\", history_folder, model_type + \"_history.csv\"), index=False\n",
    "        )\n",
    "\n",
    "    # Load the model from disk if it is already trained\n",
    "    else:\n",
    "        imgsize = input_size(model_type)\n",
    "        model = build_model(model_type= model_type, input_shape=(size, size, 3), hidden_layer_size=2, activation_function=\"relu\", learning_rate=0.001, dropout_rate=0)\n",
    "        model_path = os.path.join(\".\", models_folder, model_type + \".hdf5\")\n",
    "        model.load_weights(model_path)\n",
    "        print(\"Loaded model {} from disk\".format(model_type))\n",
    "\n",
    "    # Skip testing if there was an error in training the model\n",
    "    if error_flag:\n",
    "        continue\n",
    "\n",
    "    gc.collect()\n",
    "    k.clear_session()\n",
    "\n",
    "if len(models_failed) == 0:\n",
    "    print(\"Models that failed training:\")\n",
    "    for fail in models_failed:\n",
    "        print(\"\\t\" + fail)\n",
    "else:\n",
    "    print(\"All models have been initialised!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction for EfficientNetB0\n",
      "Found 42144 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(model_type\u001b[38;5;241m=\u001b[39m model_type, input_shape\u001b[38;5;241m=\u001b[39m(size, size, \u001b[38;5;241m3\u001b[39m), hidden_layer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, activation_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, models_folder, model_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m from disk\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_type))\n\u001b[1;32m     27\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_generator, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_generator), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/fyp/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/fyp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:655\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    590\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    Returns an array with axes transposed.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fyp/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "# Specify the path to the test data\n",
    "test_path = os.path.join(\".\", data_folder, \"Test\")\n",
    "\n",
    "# Test the models\n",
    "for model_type in model_list:\n",
    "    print(\"Starting prediction for\", model_type)\n",
    "    test_img_gen = ImageDataGenerator(\n",
    "        preprocessing_function=efn.preprocess_input\n",
    "    )\n",
    "\n",
    "    imgsize = input_size(model_type)\n",
    "\n",
    "    test_generator = test_img_gen.flow_from_directory(\n",
    "        directory=test_path,\n",
    "        target_size=(imgsize, imgsize),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        seed=123,\n",
    "    )\n",
    "\n",
    "    model = build_model(model_type= model_type, input_shape=(size, size, 3), hidden_layer_size=2, activation_function=\"relu\", learning_rate=0.001, dropout_rate=0)\n",
    "    model_path = os.path.join(\".\", models_folder, model_type + \".hdf5\")\n",
    "    model.load_weights(model_path)\n",
    "    print(\"Loaded model {} from disk\".format(model_type))\n",
    "\n",
    "    predicted = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "    predicted_class_indices = np.argmax(predicted, axis=1)\n",
    "    y = test_generator.classes\n",
    "\n",
    "    Accuracy = metrics.accuracy_score(y, predicted_class_indices)\n",
    "    print(\"Model Accuracy: \", Accuracy)\n",
    "\n",
    "    Precision = metrics.precision_score(y, predicted_class_indices, average=\"binary\")\n",
    "    print(\"Model Precision: \", Precision)\n",
    "\n",
    "    Recall = metrics.recall_score(y, predicted_class_indices, average=\"binary\")\n",
    "    print(\"Model Recall: \", Recall)\n",
    "\n",
    "    Auc = metrics.roc_auc_score(y, predicted_class_indices)\n",
    "    print(\"AUC: \", Auc, \"\\n\")\n",
    "\n",
    "    models_result[model_type] = {\n",
    "        \"Accuracy\": Accuracy,\n",
    "        \"Precision\": Precision,\n",
    "        \"Recall\": Recall,\n",
    "        \"AUC\": Auc,\n",
    "    }\n",
    "\n",
    "    filenames = [os.path.split(i)[1] for i in test_generator.filenames]\n",
    "    actualLabel = [os.path.split(i)[0] for i in test_generator.filenames]\n",
    "\n",
    "    for i in range(len(actualLabel)):\n",
    "        if actualLabel[i] == \"manipulated\":\n",
    "            actualLabel[i] = \"0\"\n",
    "        else:\n",
    "            actualLabel[i] = \"1\"\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": pd.Series(filenames),\n",
    "            \"actual label\": pd.Series(actualLabel),\n",
    "            \"pred label\": pd.Series(predicted_class_indices),\n",
    "        }\n",
    "    )\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "    results_df.to_csv(os.path.join(\".\", result_folder, model_type + \"_out.csv\"))\n",
    "\n",
    "with open(os.path.join(\".\", result_folder, \"model_results.json\"), \"w\") as outfile:\n",
    "    json.dump(models_result, outfile)\n",
    "\n",
    "model_prediction_results = pd.DataFrame.from_dict(models_result, orient=\"index\")\n",
    "model_prediction_results.to_csv(\n",
    "    os.path.join(\".\", result_folder, \"prediction_results.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 2 dimensional dataframe out of the given data\n",
    "results_df = pd.read_csv(os.path.join(\".\", result_folder, \"prediction_results.csv\"))\n",
    "results_df = results_df.rename(columns={\"Unnamed: 0\": \"Model\"})\n",
    "\n",
    "\n",
    "# Set the model names as the index for better labeling on the x-axis\n",
    "results_df.set_index(\"Model\", inplace=True)\n",
    "\n",
    "results_df_transposed = results_df.transpose()\n",
    "\n",
    "# Create a bar plot for the DataFrame\n",
    "ax = results_df_transposed.plot(kind=\"bar\", figsize=(12, 8))\n",
    "ax.set_ylabel(\"Scores\")\n",
    "# ax.set_xlabel('Metrics')\n",
    "ax.set_title(\"Model Evaluation Metrics\")\n",
    "\n",
    "# Set the y-axis lower limit to 0.90\n",
    "ax.set_ylim(0.70, 1.0)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1), ncol=1)\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "\n",
    "# Bold the fonts in the graph\n",
    "matplotlib.rcParams[\"font.weight\"] = \"bold\"\n",
    "matplotlib.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "matplotlib.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=11, width=2, length=6)\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "ax.set_xticklabels([])\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "table(ax, results_df.round(4), loc=\"bottom\", cellLoc=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the test data\n",
    "test_path = os.path.join(\".\", data_folder, \"Test\")\n",
    "\n",
    "# Test the models\n",
    "model_type = \"EfficientNetB0\"\n",
    "print(\"Starting prediction for\", model_type)\n",
    "test_img_gen = ImageDataGenerator(\n",
    "    preprocessing_function=efn.preprocess_input\n",
    ")\n",
    "\n",
    "imgsize = input_size(model_type)\n",
    "\n",
    "test_generator = test_img_gen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(imgsize, imgsize),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "model = build_model(model_type,(imgsize, imgsize, 3))\n",
    "model.load_weights(\"/home/FYP/dion0020/deepfake-detector/dev/Benchmark Models/best_tuned_model.hdf5\")\n",
    "print(\"Loaded model {} from disk\".format(model_type))\n",
    "\n",
    "predicted = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "predicted_class_indices = np.argmax(predicted, axis=1)\n",
    "y = test_generator.classes\n",
    "\n",
    "Accuracy = metrics.accuracy_score(y, predicted_class_indices)\n",
    "print(\"Model Accuracy: \", Accuracy)\n",
    "\n",
    "Precision = metrics.precision_score(y, predicted_class_indices, average=\"binary\")\n",
    "print(\"Model Precision: \", Precision)\n",
    "\n",
    "Recall = metrics.recall_score(y, predicted_class_indices, average=\"binary\")\n",
    "print(\"Model Recall: \", Recall)\n",
    "\n",
    "Auc = metrics.roc_auc_score(y, predicted_class_indices)\n",
    "print(\"AUC: \", Auc, \"\\n\")\n",
    "\n",
    "models_result[model_type] = {\n",
    "    \"Accuracy\": Accuracy,\n",
    "    \"Precision\": Precision,\n",
    "    \"Recall\": Recall,\n",
    "    \"AUC\": Auc,\n",
    "}\n",
    "\n",
    "filenames = [os.path.split(i)[1] for i in test_generator.filenames]\n",
    "actualLabel = [os.path.split(i)[0] for i in test_generator.filenames]\n",
    "\n",
    "for i in range(len(actualLabel)):\n",
    "    if actualLabel[i] == \"manipulated\":\n",
    "        actualLabel[i] = \"0\"\n",
    "    else:\n",
    "        actualLabel[i] = \"1\"\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": pd.Series(filenames),\n",
    "        \"actual label\": pd.Series(actualLabel),\n",
    "        \"pred label\": pd.Series(predicted_class_indices),\n",
    "    }\n",
    ")\n",
    "os.makedirs(result_folder, exist_ok=True)\n",
    "results_df.to_csv(os.path.join(\".\", result_folder, model_type + \"_out.csv\"))\n",
    "\n",
    "with open(os.path.join(\".\", result_folder, \"model_results.json\"), \"w\") as outfile:\n",
    "    json.dump(models_result, outfile)\n",
    "\n",
    "model_prediction_results = pd.DataFrame.from_dict(models_result, orient=\"index\")\n",
    "model_prediction_results.to_csv(\n",
    "os.path.join(\".\", result_folder, \"prediction_results.csv\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
