{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27735/1029250346.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-04-22 23:26:31.941331: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/tmp/ipykernel_27735/1029250346.py:29: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats(\"svg\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.display import set_matplotlib_formats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "from common.model_utils import build_model, input_size\n",
    "from tensorflow.keras.applications import efficientnet as efn\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "# from common.landmark_model_utils import build_model_landmarks\n",
    "\n",
    "# import packages and modules for graph plotting\n",
    "from pandas.plotting import table\n",
    "\n",
    "# setup output image format (Chrome works best)\n",
    "set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Training Data\"\n",
    "landmark_data_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Training Landmarks Data\"\n",
    "result_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Result\"\n",
    "landmark_result_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Landmark Result\"\n",
    "models_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Benchmark Models\"\n",
    "landmark_models_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Landmark Models\"\n",
    "# landmark_models_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Landmark Models/old\"\n",
    "tuning_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Tuning\"\n",
    "landmark_tuning_folder = \"/home/FYP/dion0020/deepfake-detector/dev/Landmark Tuning\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "LANDMARK = True\n",
    "model_type = \"EfficientNetB0\"\n",
    "models_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hyperparameters_file(file_path):\n",
    "    # Initialize an empty dictionary to store hyperparameters\n",
    "    hyperparameters = {}\n",
    "\n",
    "    try:\n",
    "        # Open the file and read its contents\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read each line in the file\n",
    "            for line in file:\n",
    "                # Split each line into key-value pairs\n",
    "                key, value = line.strip().split(': ')\n",
    "                # Store the key-value pair in the dictionary\n",
    "                hyperparameters[key] = value\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if LANDMARK:\n",
    "    tuning_dir = landmark_tuning_folder\n",
    "    data_dir = landmark_data_folder\n",
    "    model_dir = landmark_models_folder\n",
    "    result_dir = landmark_result_folder\n",
    "else:\n",
    "    tuning_dir = tuning_folder\n",
    "    data_dir = data_folder\n",
    "    model_dir = models_folder\n",
    "    result_dir = result_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_misclassified_images(actual_labels, predicted_labels, filenames, src_dir, dest_dir):\n",
    "    for i in range(len(actual_labels)):\n",
    "        if actual_labels[i] != predicted_labels[i]:\n",
    "            if filenames[i].split('_')[0] == \"faked\":\n",
    "                file = \"manipulated\"\n",
    "            else:\n",
    "                file = \"original\"\n",
    "            shutil.copy(os.path.join(src_dir, f\"{file}/{filenames[i]}\"), os.path.join(dest_dir, filenames[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File '/home/FYP/dion0020/deepfake-detector/dev/Landmark Tuning/EfficientNetB0 Tuning/EfficientNetB0_best_hyperparameters.txt' not found.\n",
      "Starting prediction for EfficientNetB0\n",
      "Found 42144 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 23:26:39.132716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-22 23:26:39.132747: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-22 23:26:39.132780: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SCSEGPU-TC1): /proc/driver/nvidia/version does not exist\n",
      "2024-04-22 23:26:39.133339: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'invert')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m imgsize \u001b[38;5;241m=\u001b[39m input_size(model_type)\n\u001b[1;32m     23\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_img_gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     24\u001b[0m     directory\u001b[38;5;241m=\u001b[39mtest_path,\n\u001b[1;32m     25\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(imgsize, imgsize),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m from disk\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_type))\n\u001b[1;32m     36\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.conda/envs/fyp2/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/fyp2/lib/python3.10/site-packages/keras/utils/generic_utils.py:1174\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1173\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'invert')"
     ]
    }
   ],
   "source": [
    "# file_path = f\"{tuning_dir}/{model_type} Tuning/{model_type}_best_hyperparameters.txt\"\n",
    "model_path = os.path.join(\".\", model_dir, f\"{model_type}\" + \".hdf5\")\n",
    "# model_path = \"/home/FYP/dion0020/deepfake-detector/dev/Landmark Models/old/EfficientNetB0.hdf5\"\n",
    "# best_hp = read_hyperparameters_file(file_path)\n",
    "\n",
    "# Specify the path to the test data\n",
    "test_path = os.path.join(\".\", data_dir, \"Test\")\n",
    "\n",
    "total_prediction_time = 0\n",
    "\n",
    "misclassified_images_dir = os.path.join(\".\", data_dir, \"misclassified_images\")\n",
    "if not os.path.exists(misclassified_images_dir):\n",
    "    os.makedirs(misclassified_images_dir)\n",
    "\n",
    "# Test the models\n",
    "print(\"Starting prediction for\", model_type)\n",
    "test_img_gen = ImageDataGenerator(\n",
    "    preprocessing_function=efn.preprocess_input\n",
    ")\n",
    "\n",
    "imgsize = input_size(model_type)\n",
    "\n",
    "test_generator = test_img_gen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(imgsize, imgsize),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "print(\"Loaded model {} from disk\".format(model_type))\n",
    "\n",
    "start_time = time.time()\n",
    "predicted = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = (end_time - start_time) / len(test_generator)\n",
    "predicted_class_indices = np.argmax(predicted, axis=1)\n",
    "y = test_generator.classes\n",
    "\n",
    "Accuracy = metrics.accuracy_score(y, predicted_class_indices)\n",
    "print(\"Model Accuracy: \", Accuracy)\n",
    "\n",
    "Precision = metrics.precision_score(y, predicted_class_indices, average=\"binary\")\n",
    "print(\"Model Precision: \", Precision)\n",
    "\n",
    "Recall = metrics.recall_score(y, predicted_class_indices, average=\"binary\")\n",
    "print(\"Model Recall: \", Recall)\n",
    "\n",
    "Auc = metrics.roc_auc_score(y, predicted_class_indices)\n",
    "print(\"AUC: \", Auc, \"\\n\")\n",
    "print(\"Inference Time: \", inference_time)\n",
    "\n",
    "models_result[model_type] = {\n",
    "    \"Accuracy\": Accuracy,\n",
    "    \"Precision\": Precision,\n",
    "    \"Recall\": Recall,\n",
    "    \"AUC\": Auc,\n",
    "}\n",
    "\n",
    "filenames = [os.path.split(i)[1] for i in test_generator.filenames]\n",
    "actualLabel = [os.path.split(i)[0] for i in test_generator.filenames]\n",
    "\n",
    "for i in range(len(actualLabel)):\n",
    "    if actualLabel[i] == \"manipulated\":\n",
    "        actualLabel[i] = \"0\"\n",
    "    else:\n",
    "        actualLabel[i] = \"1\"\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": pd.Series(filenames),\n",
    "        \"actual label\": pd.Series(actualLabel),\n",
    "        \"pred label\": pd.Series(predicted_class_indices),\n",
    "    }\n",
    ")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "results_df.to_csv(os.path.join(\".\", result_dir, model_type + \"_out.csv\"))\n",
    "\n",
    "with open(os.path.join(\".\", result_dir, \"model_results.json\"), \"w\") as outfile:\n",
    "    json.dump(models_result, outfile)\n",
    "\n",
    "model_prediction_results = pd.DataFrame.from_dict(models_result, orient=\"index\")\n",
    "model_prediction_results.to_csv(\n",
    "os.path.join(\".\", result_dir, \"prediction_results.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
